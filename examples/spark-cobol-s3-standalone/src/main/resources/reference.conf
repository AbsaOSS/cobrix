# Copyright 2018 ABSA Group Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

hadoop.redacted.tokens = [password, secret, session.token]

hadoop.option {
  # Authentication providerc can be
  #  - org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider
  #  - com.amazonaws.auth.profile.ProfileCredentialsProvider
  #  - com.amazonaws.auth.InstanceProfileCredentialsProvider
  # Use the default provider chain. It will use the first authentication provider that succeeds
  fs.s3a.aws.credentials.provider = "com.amazonaws.auth.DefaultAWSCredentialsProviderChain"

  # AWS credentials
  #fs.s3a.access.key = ""
  #fs.s3a.secret.key = ""
  # The session token for temporary credentials spec
  #fs.s3a.session.token = ""

  # Explicitly specify the endpoint
  #fs.s3a.endpoint = "s3.af-south-1.amazonaws.com"

  # Enable bucket key encruption
  fs.s3a.server-side-encryption-bucket-key-enabled = "true"

  # Specify the KSM key for server-side encryption
  #fs.s3a.server-side-encryption.key = "arn:aws:kms:***"
  #fs.s3a.server-side-encryption-algorithm = "SSE-KMS"
}

# Spark configuration
spark.conf.option {
  # Run Spark in local master mode
  spark.master = "local[*]"

  # You can uncomment these options if you are running under a VPN
  #spark.ui.enabled = "false"
  #spark.driver.bindAddress = "127.0.0.1"
  #spark.driver.host = "127.0.0.1"
}
